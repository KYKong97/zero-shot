{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baf4143-341e-4c0c-b8d4-b943fea10c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swinv2_moe import *\n",
    "import torch\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cc909b-2448-4fc5-bf4f-b3733d050e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = SwinTransformerV2_MOE(\n",
    "    img_size=192, embed_dim=128,depths=[ 2, 2, 18, 2 ],num_heads=[ 4, 8, 16, 32 ],window_size=12,drop_path_rate=0.3,\n",
    "    init_std=0.005,moe_blocks=[ [ -1 ], [ -1 ], [ 1, 3, 5, 7, 9, 11, 13, 15, 17 ], [ 1 ] ],cosine_router=True,\n",
    "    is_gshard_loss=False,moe_drop=0.1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1f75ae-d8f1-460d-b8ba-6338bc0132a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/losses.py:37: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  l_imp = Impi.float().var() / (Impi.float().mean() ** 2 + 1e-10)\n",
      "/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/losses.py:32: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  l_load = Load.float().var() / (Load.float().mean() ** 2 + 1e-10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'res2': tensor([[[[-3.9004e-01,  1.6235e-01, -1.7305e+00,  ...,  2.5816e-01,\n",
       "            -1.7319e+00, -4.2364e-01],\n",
       "           [-1.2039e-01, -2.4423e+00, -7.0890e-02,  ..., -7.2819e-01,\n",
       "             7.9772e-01, -4.7102e-01],\n",
       "           [ 5.3078e-01, -1.2908e-01,  1.7407e-01,  ...,  9.4864e-01,\n",
       "             5.8966e-02,  2.8417e-01],\n",
       "           ...,\n",
       "           [-3.9320e-01,  7.5186e-01,  2.1413e+00,  ..., -1.3859e+00,\n",
       "            -3.5546e-01,  3.6363e-01],\n",
       "           [ 1.3280e+00,  5.1047e-01,  1.2036e+00,  ...,  2.1838e+00,\n",
       "             7.0850e-01, -9.1300e-01],\n",
       "           [ 5.4293e-01,  5.2383e-01,  2.2768e-01,  ...,  6.4172e-01,\n",
       "             8.7042e-01, -2.7573e-01]],\n",
       " \n",
       "          [[ 1.3002e+00, -7.9164e-01,  1.2095e+00,  ..., -2.1206e-03,\n",
       "             2.8133e-01, -7.8656e-01],\n",
       "           [ 3.7323e-01,  4.4080e-01,  9.5532e-01,  ..., -1.2593e+00,\n",
       "             1.0076e+00,  1.5990e+00],\n",
       "           [ 2.3964e+00, -2.3990e-01, -1.9282e+00,  ...,  6.3284e-01,\n",
       "             1.6780e+00,  4.1085e-01],\n",
       "           ...,\n",
       "           [-1.6205e+00,  1.1721e-01, -6.2584e-01,  ...,  1.7600e+00,\n",
       "             1.5513e-01, -2.8431e-02],\n",
       "           [ 1.5184e+00,  2.6834e+00,  4.5782e-01,  ..., -1.7336e+00,\n",
       "            -1.0414e-01,  9.6936e-01],\n",
       "           [ 3.1003e-01,  1.0600e+00,  3.8517e-01,  ...,  6.3391e-01,\n",
       "            -9.4768e-01,  6.6939e-01]],\n",
       " \n",
       "          [[-3.8811e-01,  3.9545e-01,  6.4953e-02,  ...,  4.2455e-01,\n",
       "            -2.6770e+00,  1.7974e+00],\n",
       "           [-1.5654e-01, -1.4053e+00,  8.4194e-01,  ...,  1.3556e+00,\n",
       "            -1.8030e-01,  2.5910e-02],\n",
       "           [ 2.6747e-01,  1.1397e+00,  1.1040e+00,  ...,  1.1743e+00,\n",
       "             6.1149e-01, -1.5492e+00],\n",
       "           ...,\n",
       "           [ 7.8399e-01, -3.5542e-01,  4.7868e-01,  ..., -6.6313e-01,\n",
       "            -1.4761e+00, -4.1131e-01],\n",
       "           [ 1.6673e-02, -6.3511e-02,  1.5520e+00,  ...,  1.7059e-01,\n",
       "             1.4103e+00, -1.5725e+00],\n",
       "           [-3.9592e-01, -6.6613e-01,  1.1792e+00,  ..., -6.8014e-01,\n",
       "             3.0029e-01, -7.8528e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.5945e-01,  2.6647e-01, -1.7808e-01,  ..., -9.8672e-01,\n",
       "             1.3588e-02, -1.5981e-01],\n",
       "           [-1.1426e+00, -6.3197e-01,  7.1998e-01,  ..., -5.3081e-01,\n",
       "            -7.4045e-01,  1.1822e+00],\n",
       "           [ 7.5616e-01,  9.8761e-01,  1.8679e-02,  ...,  2.6990e-01,\n",
       "            -1.7230e+00, -4.0205e-02],\n",
       "           ...,\n",
       "           [-6.3445e-01,  1.8878e+00, -1.3386e-01,  ..., -2.1402e-01,\n",
       "            -4.4351e-01, -4.2843e-01],\n",
       "           [-3.8615e-02,  6.2450e-01, -1.0557e+00,  ..., -1.2662e+00,\n",
       "            -1.5438e+00, -1.0526e+00],\n",
       "           [ 1.1284e+00,  1.7882e+00, -6.1112e-01,  ..., -7.5070e-01,\n",
       "            -4.8839e-02, -4.3192e-01]],\n",
       " \n",
       "          [[-2.4461e-01, -1.4330e+00, -4.3795e-01,  ...,  1.2838e+00,\n",
       "             3.5318e-01,  4.8237e-01],\n",
       "           [ 8.7611e-01, -6.3862e-01,  9.6435e-01,  ..., -8.3342e-01,\n",
       "             1.2921e+00,  6.3893e-01],\n",
       "           [-3.4609e-01,  8.7783e-01, -1.1125e+00,  ...,  1.5848e+00,\n",
       "            -2.2558e+00,  6.0324e-01],\n",
       "           ...,\n",
       "           [-8.4857e-01,  6.1385e-02,  8.8585e-01,  ...,  9.0264e-01,\n",
       "            -1.9238e-01, -1.4376e+00],\n",
       "           [ 8.8527e-01, -1.3516e+00, -7.1094e-02,  ..., -2.5792e-01,\n",
       "            -1.3856e+00,  4.3021e-02],\n",
       "           [-3.0303e-01,  2.4282e+00, -1.8612e+00,  ...,  7.8911e-01,\n",
       "            -2.5969e-01, -8.5305e-01]],\n",
       " \n",
       "          [[ 1.3565e-01, -5.2223e-01, -6.5385e-01,  ..., -1.1866e+00,\n",
       "             1.4496e+00, -2.9391e-01],\n",
       "           [ 3.5506e-01, -6.9077e-01,  2.6952e-01,  ..., -9.8454e-01,\n",
       "            -1.0478e+00, -3.2395e-01],\n",
       "           [ 1.0548e+00,  1.8044e+00,  6.1636e-01,  ..., -1.5706e-01,\n",
       "             1.9652e+00,  2.6738e-01],\n",
       "           ...,\n",
       "           [ 1.0428e+00, -5.7330e-01,  1.4696e-01,  ..., -7.5566e-01,\n",
       "            -1.1061e+00, -4.8848e-02],\n",
       "           [-1.0730e-01, -6.4627e-01, -1.4454e-01,  ...,  5.6682e-01,\n",
       "             1.1941e+00, -1.2893e+00],\n",
       "           [-5.8253e-01, -4.3778e-01,  2.6619e-01,  ...,  1.6396e+00,\n",
       "            -1.0119e+00,  9.3149e-01]]]], grad_fn=<CloneBackward0>),\n",
       " 'res3': tensor([[[[-0.3714, -0.5262, -0.9049,  ..., -0.9306,  0.4365, -0.3541],\n",
       "           [-0.1629,  0.5364,  0.6652,  ..., -0.6671,  1.7546, -1.0830],\n",
       "           [-0.4858, -0.6473,  1.2538,  ...,  0.0029, -2.0977,  0.1395],\n",
       "           ...,\n",
       "           [-0.5721, -0.1264, -0.1603,  ..., -0.4105, -1.2490, -0.8752],\n",
       "           [ 0.0663,  1.3371,  0.4409,  ..., -1.0423,  0.9992,  0.2366],\n",
       "           [-0.5051, -0.3821, -0.1709,  ..., -0.5298, -0.4385, -1.1189]],\n",
       " \n",
       "          [[-0.3850,  1.6917,  0.0941,  ...,  0.8252,  0.4908, -0.4824],\n",
       "           [-0.2204, -0.6731,  1.3685,  ..., -0.2568, -0.7873, -1.3190],\n",
       "           [-0.4020, -1.0718, -0.1930,  ...,  0.4188,  0.0882,  0.3745],\n",
       "           ...,\n",
       "           [ 0.9540,  0.0250,  0.1367,  ..., -0.1277, -0.0661,  0.7852],\n",
       "           [-1.5861,  1.9965, -0.4813,  ...,  0.4025, -0.8731,  0.9912],\n",
       "           [ 0.1650,  1.7033,  1.7219,  ...,  0.2690,  1.6790, -1.0393]],\n",
       " \n",
       "          [[ 0.0481,  1.1083,  1.4458,  ...,  1.5245, -0.6289, -1.1711],\n",
       "           [ 0.0170,  0.0250,  0.2120,  ..., -1.4816,  1.4743, -0.5955],\n",
       "           [-0.9342,  1.1293,  0.1422,  ..., -1.1626, -0.0430,  1.0557],\n",
       "           ...,\n",
       "           [-0.4713, -0.7417,  0.8472,  ...,  1.6242, -1.1715, -0.5185],\n",
       "           [-2.2033,  1.9965, -0.9818,  ..., -1.2588, -0.4332,  1.0378],\n",
       "           [ 1.1094,  0.2551,  1.4038,  ..., -0.0993,  1.1630,  0.3096]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0284, -1.3264,  0.1459,  ..., -0.9536,  0.2965,  0.2144],\n",
       "           [-0.8630, -1.0562, -0.1676,  ..., -1.4329, -0.6181, -0.7152],\n",
       "           [ 0.6740,  1.6278,  1.7628,  ..., -0.2027,  0.4225,  1.7980],\n",
       "           ...,\n",
       "           [-1.2911,  0.5862, -0.1643,  ...,  0.1460,  1.0336, -0.2760],\n",
       "           [ 0.4057, -1.2348,  0.2218,  ...,  0.4840, -0.9249,  0.0908],\n",
       "           [ 0.1199,  0.1103,  0.2133,  ...,  1.2144,  0.6971, -0.3774]],\n",
       " \n",
       "          [[-0.5214,  1.3256,  1.1232,  ..., -1.2436,  0.8220, -0.9639],\n",
       "           [-0.9327, -1.3746,  0.5838,  ..., -0.1652, -1.3960,  0.2178],\n",
       "           [ 1.3033, -0.1520,  0.2519,  ..., -0.3182,  1.1237, -0.2123],\n",
       "           ...,\n",
       "           [ 1.8926,  0.0461,  1.7024,  ..., -0.2464, -0.0474,  0.5464],\n",
       "           [-0.3752, -0.5089, -0.9670,  ..., -0.3623, -1.2210,  2.0602],\n",
       "           [-1.5915,  0.6916, -0.7624,  ..., -1.8283,  0.5452, -0.4393]],\n",
       " \n",
       "          [[ 0.3751, -0.0636, -0.9593,  ...,  0.6936,  0.6973,  1.1790],\n",
       "           [ 0.0566, -0.1663, -1.4843,  ...,  1.7738, -0.4691,  0.3739],\n",
       "           [-0.2948,  0.1542,  1.1356,  ...,  0.8477, -0.3197,  1.7614],\n",
       "           ...,\n",
       "           [-0.9802,  0.2635, -0.8586,  ...,  0.7598,  0.0468,  0.1447],\n",
       "           [ 0.3772,  0.8336,  0.4625,  ..., -0.0931,  0.0685, -0.5135],\n",
       "           [ 0.0557, -1.2332, -0.2888,  ..., -0.6363,  1.7554,  0.5751]]]],\n",
       "        grad_fn=<CloneBackward0>),\n",
       " 'res4': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<CloneBackward0>),\n",
       " 'res5': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<CloneBackward0>)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn((1,3,640,640))\n",
    "model.forward_features(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf35956d-07b6-451e-9201-ea19b78f52f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module PatchEmbed is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module Softmax is treated as a zero-op.\n",
      "Warning: module WindowAttention is treated as a zero-op.\n",
      "Warning: module Identity is treated as a zero-op.\n",
      "Warning: module Mlp is treated as a zero-op.\n",
      "Warning: module SwinTransformerBlock is treated as a zero-op.\n",
      "Warning: module DropPath is treated as a zero-op.\n",
      "Warning: module PatchMerging is treated as a zero-op.\n",
      "Warning: module BasicLayer is treated as a zero-op.\n",
      "Warning: module FusedExpertsNetwork is treated as a zero-op.\n",
      "Warning: module CosineTopKGate is treated as a zero-op.\n",
      "Warning: module MOELayer is treated as a zero-op.\n",
      "Warning: module MoEMlp is treated as a zero-op.\n",
      "Warning: module SwinTransformerV2_MOE is treated as a zero-op.\n",
      "Flops estimation was not finished successfully because of the following exception:\n",
      "<class 'ValueError'> : Expected value argument (Tensor of shape (196, 1)) to be within the support (Real()) of the distribution Normal(loc: tensor([0.]), scale: tensor([1.])), but found invalid values:\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ptflops/pytorch_engine.py\", line 64, in get_flops_pytorch\n",
      "    _ = flops_model(batch)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1561, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/zero-shot/open_vocab_seg/modeling/backbone/swinv2_moe.py\", line 873, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"/home/zero-shot/open_vocab_seg/modeling/backbone/swinv2_moe.py\", line 845, in forward_features\n",
      "    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zero-shot/open_vocab_seg/modeling/backbone/swinv2_moe.py\", line 601, in forward\n",
      "    out = blk(x, attn_mask)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zero-shot/open_vocab_seg/modeling/backbone/swinv2_moe.py\", line 419, in forward\n",
      "    x,l_aux = self.mlp(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zero-shot/open_vocab_seg/modeling/backbone/swinv2_moe.py\", line 67, in forward\n",
      "    x = self._moe_layer(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/moe_layer.py\", line 303, in forward\n",
      "    logits_dtype, (crit, l_aux) = routing()\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/moe_layer.py\", line 287, in routing\n",
      "    return logits.dtype, extract_critical(scores,\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/fast_dispatch.py\", line 153, in extract_critical\n",
      "    l_loss = loss_fn(scores, topk_indices) if loss_fn is not None else None\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/moe_layer.py\", line 281, in <lambda>\n",
      "    _loss_fn = lambda gates, topk_ids: losses.load_importance_loss(\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/losses.py\", line 42, in load_importance_loss\n",
      "    l_load = load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise)\n",
      "  File \"/root/.local/lib/python3.10/site-packages/tutel-0.3-py3.10-linux-x86_64.egg/tutel/impls/losses.py\", line 30, in load_loss\n",
      "    prob = normal.cdf(diff)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributions/normal.py\", line 93, in cdf\n",
      "    self._validate_sample(value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py\", line 312, in _validate_sample\n",
      "    raise ValueError(\n",
      "ValueError: Expected value argument (Tensor of shape (196, 1)) to be within the support (Real()) of the distribution Normal(loc: tensor([0.]), scale: tensor([1.])), but found invalid values:\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, backend='pytorch',print_per_layer_stat=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80217dd1-afbf-48f5-b487-4426800465e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
